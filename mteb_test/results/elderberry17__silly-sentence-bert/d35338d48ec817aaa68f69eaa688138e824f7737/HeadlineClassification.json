{
  "dataset_revision": "2fe05ee6b5832cda29f2ef7aaad7b7fe6a3609eb",
  "evaluation_time": 6.317543983459473,
  "kg_co2_emissions": null,
  "mteb_version": "1.19.9",
  "scores": {
    "test": [
      {
        "accuracy": 0.567138671875,
        "f1": 0.5663145178706541,
        "f1_weighted": 0.5663524448829351,
        "hf_subset": "default",
        "languages": [
          "rus-Cyrl"
        ],
        "main_score": 0.567138671875,
        "scores_per_experiment": [
          {
            "accuracy": 0.5654296875,
            "f1": 0.5637302020377835,
            "f1_weighted": 0.5638006064973735
          },
          {
            "accuracy": 0.57470703125,
            "f1": 0.5753469544716138,
            "f1_weighted": 0.5753848561987216
          },
          {
            "accuracy": 0.57275390625,
            "f1": 0.571575484880713,
            "f1_weighted": 0.5716276456540142
          },
          {
            "accuracy": 0.50439453125,
            "f1": 0.49960886934762594,
            "f1_weighted": 0.4996537303392854
          },
          {
            "accuracy": 0.607421875,
            "f1": 0.605168395995,
            "f1_weighted": 0.6052171124654583
          },
          {
            "accuracy": 0.60107421875,
            "f1": 0.601471934614687,
            "f1_weighted": 0.6014611565520454
          },
          {
            "accuracy": 0.55859375,
            "f1": 0.5612217922504655,
            "f1_weighted": 0.5612898805504775
          },
          {
            "accuracy": 0.55517578125,
            "f1": 0.5542150619649396,
            "f1_weighted": 0.5542308796084231
          },
          {
            "accuracy": 0.5869140625,
            "f1": 0.5848773773170554,
            "f1_weighted": 0.5848731569281072
          },
          {
            "accuracy": 0.544921875,
            "f1": 0.5459291058266578,
            "f1_weighted": 0.5459854240354461
          }
        ]
      }
    ]
  },
  "task_name": "HeadlineClassification"
}