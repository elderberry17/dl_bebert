# BeBertDecoder

This branch demonstrates an architecture of simple GPT model.

The difference is in attention calculation, loss and train loop.

You are free to add new data and tune training params for better quality.